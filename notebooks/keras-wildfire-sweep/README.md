# Обучение модели с помощью Keras с использованием размеченного датасета

## Используемый датасет
https://www.kaggle.com/datasets/abdelghaniaaba/wildfire-prediction-dataset/data

## Описание модели глубокого обучения
### Тип модели
Модель: Сверточная нейронная сеть (CNN)
### Архитектура  
Входные данные: Изображения размером 32x32 пикселя с 3 цветными каналами (RGB).  
Слои:  
Сверточные слои:  
1-й слой: Conv2D с 32 фильтрами, размер ядра (3, 3), активация ReLU  
2-й слой: Conv2D с 64 фильтрами, размер ядра (3, 3), активация ReLU, padding='same'  
3-й слой: Conv2D с 64 фильтрами, размер ядра (3, 3), активация ReLU, padding='same'  
4-й слой: Conv2D с 128 фильтрами, размер ядра (3, 3), активация ReLU, padding='same'  
5-й слой: Conv2D с 128 фильтрами, размер ядра (3, 3), активация ReLU, padding='same'  
6-й слой: Conv2D с 256 фильтрами, размер ядра (3, 3), активация ReLU, padding='same'  
7-й слой: Conv2D с 256 фильтрами, размер ядра (3, 3), активация ReLU, padding='same'  
8-й слой: Conv2D с 128 фильтрами, размер ядра (3, 3), активация ReLU, padding='same'  
9-й слой: Conv2D с 128 фильтрами, размер ядра (3, 3), активация ReLU, padding='same'  
Слои нормализации: BatchNormalization после некоторых сверточных слоев для улучшения сходимости.  
Слои подвыборки: MaxPooling2D после каждого блока сверточных слоев для уменьшения размерности.  
Полносвязные слои:  
Flatten для преобразования выходов сверточных слоев в одномерный вектор.  
1-й Dense слой: 128 нейронов, активация ReLU  
2-й Dense слой: 128 нейронов, активация ReLU  
Dropout (0.5) для регуляризации.  
3-й Dense слой: 64 нейрона, активация ReLU  
4-й Dense слой: 32 нейрона, активация ReLU  
Выходной слой: Dense с 1 нейроном и активацией Sigmoid для бинарной классификации.  
### Общее количество параметров  
Общее количество параметров: 1,782,529  
Обучаемые параметры: 1,781,313  
Необучаемые параметры: 1,216  
### Гиперпараметры  
Оптимизатор: Adam  
Функция потерь: Binary Crossentropy  
Метрики: Accuracy  
Размер мини-партии: 64  
Количество эпох: 5  
EarlyStopping: Мониторинг val_loss с терпимостью 4.  
### Данные для обучения  
Обучающий набор: 30,250 изображений  
Проверочный набор: 6,300 изображений  
Тестовый набор: 6,300 изображений  
Классы: "wildfire" (1) и "nowildfire" (0)    

## Результаты тестирования  
Тестовая точность: 95.33%  
Точность на обучающем наборе: 94%  
Точность на проверочном наборе: 94%  

## Метрики для классов:  
### Обучение:  
Precision: 0.99 (для класса 0), 0.90 (для класса 1)  
Recall: 0.88 (для класса 0), 0.99 (для класса 1)  
F1-score: 0.93 (для класса 0), 0.94 (для класса 1)  
### Проверка:  
Precision: 0.98 (для класса 0), 0.92 (для класса 1)  
Recall: 0.89 (для класса 0), 0.98 (для класса 1)  
F1-score: 0.93 (для класса 0), 0.95 (для класса 1)  
### Тест:  
Precision: 0.98 (для класса 0), 0.93 (для класса 1)  
Recall: 0.91 (для класса 0), 0.99 (для класса 1)  
F1-score: 0.95 (для класса 0), 0.96 (для класса 1)  

**classification report for test :** 
```
              precision    recall  f1-score   support

           0       0.98      0.91      0.95      2820
           1       0.93      0.99      0.96      3480

    accuracy                           0.95      6300
   macro avg       0.96      0.95      0.95      6300
weighted avg       0.95      0.95      0.95      6300
```
