{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c028099b-81b3-4415-90ea-89b354b7d64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34e88da5-4de1-4465-8767-6538929bfb73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.49 üöÄ Python-3.11.5 torch-2.2.2 CPU (Intel Core(TM) i5-5350U 1.80GHz)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolo11x-cls.pt, data=/Users/marinasemushina/Desktop/task, epochs=3, time=None, patience=100, batch=16, imgsz=128, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/train2\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /Users/marinasemushina/Desktop/task/train... found 30250 images in 2 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m None...\n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /Users/marinasemushina/Desktop/task/test... found 6300 images in 2 classes ‚úÖ \n",
      "Overriding model.yaml nc=80 with nc=2\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      2784  ultralytics.nn.modules.conv.Conv             [3, 96, 3, 2]                 \n",
      "  1                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  2                  -1  2    389760  ultralytics.nn.modules.block.C3k2            [192, 384, 2, True, 0.25]     \n",
      "  3                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      "  4                  -1  2   1553664  ultralytics.nn.modules.block.C3k2            [384, 768, 2, True, 0.25]     \n",
      "  5                  -1  1   5309952  ultralytics.nn.modules.conv.Conv             [768, 768, 3, 2]              \n",
      "  6                  -1  2   5022720  ultralytics.nn.modules.block.C3k2            [768, 768, 2, True]           \n",
      "  7                  -1  1   5309952  ultralytics.nn.modules.conv.Conv             [768, 768, 3, 2]              \n",
      "  8                  -1  2   5022720  ultralytics.nn.modules.block.C3k2            [768, 768, 2, True]           \n",
      "  9                  -1  2   3264768  ultralytics.nn.modules.block.C2PSA           [768, 768, 2]                 \n",
      " 10                  -1  1    988162  ultralytics.nn.modules.head.Classify         [768, 2]                      \n",
      "YOLO11x-cls summary: 309 layers, 28,358,626 parameters, 28,358,626 gradients, 111.0 GFLOPs\n",
      "Transferred 492/494 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/classify/train2', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /Users/marinasemushina/Desktop/task/train... 30249 images, 1 cor\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ‚ö†Ô∏è /Users/marinasemushina/Desktop/task/train/nowildfire/-114.152378,51.027198.jpg: ignoring corrupt image/label: image file is truncated (18 bytes not processed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /Users/marinasemushina/Desktop/task/test... 6299 images, 1 corrupt\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ‚ö†Ô∏è /Users/marinasemushina/Desktop/task/test/wildfire/-73.15884,46.38819.jpg: ignoring corrupt image/label: image file is truncated (56 bytes not processed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 82 weight(decay=0.0), 83 weight(decay=0.0005), 83 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\n",
      "Image sizes 128 train, 128 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns/classify/train2\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3         0G     0.2202          9        128: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1891/1\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 197/197 [18:18<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.978          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3         0G     0.1395          9        128: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1891/1\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 197/197 [09:52<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.962          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3         0G    0.09707          9        128: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1891/1\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 197/197 [08:34<00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.989          1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 11.616 hours.\n",
      "Optimizer stripped from runs/classify/train2/weights/last.pt, 57.0MB\n",
      "Optimizer stripped from runs/classify/train2/weights/best.pt, 57.0MB\n",
      "\n",
      "Validating runs/classify/train2/weights/best.pt...\n",
      "Ultralytics 8.3.49 üöÄ Python-3.11.5 torch-2.2.2 CPU (Intel Core(TM) i5-5350U 1.80GHz)\n",
      "YOLO11x-cls summary (fused): 227 layers, 28,334,978 parameters, 0 gradients, 110.3 GFLOPs\n",
      "WARNING ‚ö†Ô∏è Dataset 'split=val' not found, using 'split=test' instead.\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /Users/marinasemushina/Desktop/task/train... found 30250 images in 2 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m None...\n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /Users/marinasemushina/Desktop/task/test... found 6300 images in 2 classes ‚úÖ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 197/197 [08:02<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.989          1\n",
      "Speed: 0.0ms preprocess, 68.8ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/classify/train2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(model='yolo11x-cls.pt')\n",
    "results = model.train(data='/Users/marinasemushina/Desktop/task', epochs=3, imgsz=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03e4edd2-1ea1-4c3c-b1e9-2b2a7e7cd4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ó–∞–≥—Ä—É–∂–∞–µ–º –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è\n",
    "model = YOLO('/Users/marinasemushina/Desktop/task/best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "253272f4-5d59-4edd-85e4-09349ed2d83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü—É—Ç—å –∫ —Ç–µ—Å—Ç–æ–≤—ã–º –¥–∞–Ω–Ω—ã–º\n",
    "test_data_path = '/Users/marinasemushina/Desktop/task/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5dbcf675-d39a-4d5a-beb2-728ed7ab8e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–°–ø–∏—Å–∫–∏ —Å–æ–∑–¥–∞–Ω—ã\n"
     ]
    }
   ],
   "source": [
    "# –°–æ–∑–¥–∞–µ–º —Å–ø–∏—Å–∫–∏ –¥–ª—è –∏—Å—Ç–∏–Ω–Ω—ã—Ö –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫\n",
    "y_true = []  # –ò—Å—Ç–∏–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ –∫–ª–∞—Å—Å–æ–≤\n",
    "y_pred = []  # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –æ—Ç –º–æ–¥–µ–ª–∏\n",
    "\n",
    "# –ü–æ–ª—É—á–∞–µ–º –∏–º–µ–Ω–∞ –∫–ª–∞—Å—Å–æ–≤\n",
    "class_names = sorted(os.listdir(test_data_path))\n",
    "\n",
    "# –ó–∞–ø–æ–ª–Ω—è–µ–º y_true –∏ y_pred\n",
    "for label, class_name in enumerate(class_names):\n",
    "    class_path = os.path.join(test_data_path, class_name)\n",
    "    if os.path.isdir(class_path):\n",
    "        for img_file in os.listdir(class_path):\n",
    "            path = os.path.join(class_path, img_file)\n",
    "            y_true.append(label)\n",
    "            # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –æ—Ç –º–æ–¥–µ–ª–∏\n",
    "            prediction = model.predict(path, save=False, verbose=False)[0]\n",
    "            y_pred.append(prediction.probs.top1)  # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è, —á—Ç–æ —ç—Ç–æ –∏–Ω–¥–µ–∫—Å –∫–ª–∞—Å—Å–∞\n",
    "\n",
    "print('–°–ø–∏—Å–∫–∏ —Å–æ–∑–¥–∞–Ω—ã')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd73940f-a321-4b10-bed9-4dc7952d7c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.49 üöÄ Python-3.11.5 torch-2.2.2 CPU (Intel Core(TM) i5-5350U 1.80GHz)\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m /Users/marinasemushina/Desktop/task/train... found 30250 images in 2 classes ‚úÖ \n",
      "\u001b[34m\u001b[1mval:\u001b[0m None...\n",
      "\u001b[34m\u001b[1mtest:\u001b[0m /Users/marinasemushina/Desktop/task/test... found 6300 images in 2 classes ‚úÖ \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning /Users/marinasemushina/Desktop/task/test... 6299 images, 1 corrup\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ‚ö†Ô∏è /Users/marinasemushina/Desktop/task/test/wildfire/-73.15884,46.38819.jpg: ignoring corrupt image/label: image file is truncated (56 bytes not processed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "               classes   top1_acc   top5_acc: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 394/394 [09:47<00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.989          1\n",
      "Speed: 0.0ms preprocess, 84.3ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/classify/val4\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# –û—Ü–µ–Ω–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö\n",
    "metrics = model.val(data='/Users/marinasemushina/Desktop/task/', split='test', verbose=False)\n",
    "test_accuracy = metrics.top1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf14f313-e05d-4819-aafc-fc3e64a7e084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  nowildfire       0.99      0.98      0.99      2820\n",
      "    wildfire       0.99      0.99      0.99      3480\n",
      "\n",
      "    accuracy                           0.99      6300\n",
      "   macro avg       0.99      0.99      0.99      6300\n",
      "weighted avg       0.99      0.99      0.99      6300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# –§–æ—Ä–º–∏—Ä—É–µ–º classification report –ø—Ä–∏ –ø–æ–º–æ—â–∏ sklearn\n",
    "target_names = class_names  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∏–º–µ–Ω–∞ –∫–ª–∞—Å—Å–æ–≤ –¥–ª—è –æ—Ç—á–µ—Ç–∞\n",
    "report = classification_report(y_true, y_pred, target_names=target_names)\n",
    "\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb1543c5-a559-452b-b014-7ff3a89a663a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9892046451568604\n",
      "Precision: 0.9892159793214295\n",
      "Recall: 0.9892063492063492\n",
      "F1 Score: 0.9892029914532716\n"
     ]
    }
   ],
   "source": [
    "# –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏\n",
    "precision = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "recall = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "print(f\"Accuracy: {test_accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f679a4ed-7db8-4429-b82e-e30bc7c58e52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
